{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fixDataLength(path):\n",
    "    '''\n",
    "    gets rid of the weird length stuff\n",
    "    path (string) : filepath to the .log file for a participant\n",
    "    '''     \n",
    "    x = open(path)\n",
    "    s = x.read().replace(',,,', ',NaN,NaN,')\n",
    "    x.close()\n",
    "\n",
    "    # Now open the file in write mode and write the string with replaced\n",
    "\n",
    "    x=open(path,'w')\n",
    "    x.write(s)\n",
    "    x.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAccAndRT(df):\n",
    "    '''\n",
    "    returns [array]: [reaction time, accuracy] for dataframe df\n",
    "    df needs to have ['respTime'] and ['accuracy'] columns, and a name\n",
    "    '''\n",
    "    accCount = df['accuracy'].astype(int).sum()\n",
    "\n",
    "    accPerc = accCount / len(df)\n",
    "    RT = df['respTime'].astype(float).mean()\n",
    "    \n",
    "    print(df.name + ' AccPerc is ' + str(accPerc))\n",
    "    print(df.name + ' avg resp time: ' + str(RT))\n",
    "    \n",
    "    return [accPerc, RT]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a10ij5ugn53ua7 exists.\n",
      "a28d99x06zi4as exists.\n",
      "a9mjvjamlcdmv exists.\n",
      "a3gvuyy3twrpzt exists.\n",
      "a1o7wvjlbkcx1a exists.\n",
      "a3su002smrt617 exists.\n",
      "a2tc7b46wq695o exists.\n",
      "a1utnak70qh9js exists.\n",
      "a1rv2lervs0a4h exists.\n",
      "awsg11rh1py2i exists.\n",
      "a3cimzpg2oy5zo exists.\n",
      "a3ljsvb3hlepnw exists.\n",
      "a1s6rzmvtbgzre exists.\n",
      "ajabapm32etmn exists.\n",
      "Creating group level csv file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 2: expected 24 fields, saw 76\\nSkipping line 3: expected 24 fields, saw 26\\nSkipping line 4: expected 24 fields, saw 26\\nSkipping line 5: expected 24 fields, saw 26\\nSkipping line 6: expected 24 fields, saw 26\\nSkipping line 7: expected 24 fields, saw 26\\nSkipping line 8: expected 24 fields, saw 26\\nSkipping line 9: expected 24 fields, saw 26\\nSkipping line 10: expected 24 fields, saw 26\\nSkipping line 11: expected 24 fields, saw 26\\nSkipping line 12: expected 24 fields, saw 26\\nSkipping line 13: expected 24 fields, saw 26\\nSkipping line 14: expected 24 fields, saw 26\\nSkipping line 15: expected 24 fields, saw 26\\nSkipping line 16: expected 24 fields, saw 26\\nSkipping line 17: expected 24 fields, saw 26\\nSkipping line 18: expected 24 fields, saw 26\\nSkipping line 19: expected 24 fields, saw 26\\nSkipping line 20: expected 24 fields, saw 26\\nSkipping line 21: expected 24 fields, saw 26\\nSkipping line 22: expected 24 fields, saw 26\\nSkipping line 23: expected 24 fields, saw 26\\nSkipping line 24: expected 24 fields, saw 26\\n'\n",
      "/Users/jinjiang-macair/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:65: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import copy\n",
    "\n",
    "#global script variables\n",
    "accCutoff = .65\n",
    "path = r'/Users/jinjiang-macair/Library/CloudStorage/OneDrive-DukeUniversity/Duke/Fall2022Rotation/Data/contextFlanker/'\n",
    "\n",
    "#load files from path\n",
    "allFiles = glob.glob(path + \"*.txt\")\n",
    "assignmentID = allFiles\n",
    "subjectList = []\n",
    "assignmentList = []\n",
    "groupDataList = []\n",
    "aboveAccCutoff = []\n",
    "accList = []\n",
    "\n",
    "for file in allFiles:\n",
    "    # open participant info file\n",
    "    partInfoFile = open(file,\"r\").readlines()\n",
    "    partInfo = [x.strip() for x in partInfoFile]\n",
    "    \n",
    "    #pull worker ID and assignment ID from file\n",
    "    wID = partInfo[2]\n",
    "    aID = partInfo[1]\n",
    "    compID = wID.split(':')  #getting worker ID\n",
    "    compID2 = aID.split(':') #getting assignment ID\n",
    "    subject = compID[1] #subID\n",
    "    \n",
    "    #open log file with the same name as the given particant info file\n",
    "    logfile = compID2[1]+'.log'\n",
    "    \n",
    "    fixDataLength(path+logfile) #dunno if i should return the log file instead of doing a void fxn here\n",
    "    \n",
    "    partDataFile = pd.read_csv(path + logfile, lineterminator=';', sep=',', header=None, error_bad_lines = False);\n",
    "    partData = pd.concat([partDataFile], ignore_index=True, axis = 1) \n",
    "    testData = copy.deepcopy(partData)\n",
    "    \n",
    "    #formatting result dataframe\n",
    "    \n",
    "    # these are longer than they seem.\n",
    "    partData['subject']=subject #adding a column with subID\n",
    "    partData = partData.rename(columns={0: 'sectionType', 1: 'taskName', 2: 'blockNumber', 3: 'firstBlockName', 4: 'secondBlockName', 5: 'thirdBlockName', \n",
    "                                        6:'currentBlockName', 7: 'trialCount', 8: 'blockTrialCount', \n",
    "                                        9: 'trialImg', 10: 'imgSource', 11:'imgCongruency', 13: 'imgDisplayLocation', 13:'repeat', \n",
    "                                        14: 'stimOnset', 15: 'respOnset', 16: 'respTime', 17: 'accuracy', 18: 'redundantDispLoc', 19: 'redundantCongruency',\n",
    "                                        20: 'sectionStart', 21: 'sectionEnd', 22: 'sectionEnd-sectionStart', 23: 'useless1', 24: 'useless2', 25: 'useless3', 26:'subject'}) \n",
    "       \n",
    "    #add info to individual lists\n",
    "    subjectList.append(subject)\n",
    "    assignmentList.append(compID2[1])\n",
    "    \n",
    "    #add data to whole sample dataframe list\n",
    "    groupDataList.append(partData)\n",
    "\n",
    "    #save out participant data to CSV if it doesn't exist already\n",
    "    if os.path.exists(path+'Subj_'+str(subject)+'.csv'):\n",
    "        print(subject+' exists.') #don't make csv again if it already exits (file creation times are helpful for keeping track of data)\n",
    "    else:\n",
    "        print('Creating csv file for '+subject)\n",
    "        partData.to_csv(path+'Subj_'+str(subject)+'.csv', index=False)\n",
    "    \n",
    "#combine groupData into one file and save file\n",
    "groupData = pd.concat(groupDataList, ignore_index = True)\n",
    "\n",
    "# save out groupData into csv\n",
    "print('Creating group level csv file.')\n",
    "groupData.to_csv(path+'combinedData'+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/jinjiang-macair/Library/CloudStorage/OneDrive-DukeUniversity/Duke/Fall2022Rotation/ContextCognitiveControlCode/analysis/test2.log'\n",
    "x = open(path)\n",
    "s = x.read().replace(';', '\\n')\n",
    "x.close()\n",
    "\n",
    "# Now open the file in write mode and write the string with replaced\n",
    "\n",
    "x=open(path,'w')\n",
    "x.write(s)\n",
    "x.close()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find a way to replace all characters in one go cuz this is so dumb\n",
    "path = '/Users/jinjiang-macair/Library/CloudStorage/OneDrive-DukeUniversity/Duke/Fall2022Rotation/ContextCognitiveControlCode/analysis/test2.log'\n",
    "x = open(path)\n",
    "s = x.read().replace('test,,', 'test,test,')\n",
    "x.close()\n",
    "\n",
    "# Now open the file in write mode and write the string with replaced\n",
    "\n",
    "x=open(path,'w')\n",
    "x.write(s)\n",
    "x.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# also delete all the practice trials cuz their lengths are messed up rn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find a way to replace all characters in one go cuz this is so dumb\n",
    "path = '/Users/jinjiang-macair/Library/CloudStorage/OneDrive-DukeUniversity/Duke/Fall2022Rotation/ContextCognitiveControlCode/analysis/test2.log'\n",
    "x = open(path)\n",
    "s = x.read().replace(',,,', ',NaN,NaN,')\n",
    "x.close()\n",
    "\n",
    "# Now open the file in write mode and write the string with replaced\n",
    "\n",
    "x=open(path,'w')\n",
    "x.write(s)\n",
    "x.close()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "allData = pd.read_csv('/Users/jinjiang-macair/Library/CloudStorage/OneDrive-DukeUniversity/Duke/Fall2022Rotation/Data/contextFlanker/combinedData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg con resp time: 1067.6666666666667\n",
      "avg inc resp time: 1079.307126258714\n"
     ]
    }
   ],
   "source": [
    "print('avg con resp time: ' + str(conDF['respTime'].astype(float).mean()))\n",
    "\n",
    "print('avg inc resp time: ' + str(incDF['respTime'].astype(float).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "accThreshold = 75\n",
    "\n",
    "highAccDF = pd.DataFrame()\n",
    "\n",
    "subjectList.remove('a3ljsvb3hlepnw')\n",
    "\n",
    "for subject in subjectList:\n",
    "    subjectDF = allData.loc[allData['subject'] == subject]\n",
    "    \n",
    "    '''\n",
    "    Check if the accuracy of each subject is above our threshold.\n",
    "    If so, add it to the highAccDF.\n",
    "    '''\n",
    "    if (100 * subjectDF['accuracy'].astype(int).sum() / len(subjectDF)) > accThreshold:\n",
    "        highAccDF = pd.concat([highAccDF, subjectDF])\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conAccPerc is 0.8658064516129033\n",
      "incAccPerc is: 0.8407479045776918\n"
     ]
    }
   ],
   "source": [
    "conDF = highAccDF.loc[(highAccDF['imgCongruency'] == 'c')]\n",
    "\n",
    "incDF = highAccDF.loc[(highAccDF['imgCongruency'] == 'i')]\n",
    "\n",
    "\n",
    "conAccCount = conDF['accuracy'].astype(int).sum()\n",
    "incAccCount = incDF['accuracy'].astype(int).sum()\n",
    "\n",
    "\n",
    "\n",
    "conAccPerc = conAccCount / len(conDF)\n",
    "incAccPerc = incAccCount / len(incDF)\n",
    "\n",
    "print('conAccPerc is ' + str(conAccPerc))\n",
    "\n",
    "print('incAccPerc is: ' + str(incAccPerc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to grab the respTime and Acc for each trial AFTER a congruent trial\n",
    "\n",
    "\n",
    "# make an empty dataframe for trials AFTER congruent ones\n",
    "# make another empty dataframe for trials after incongruent ones\n",
    "\n",
    "# for each row in the test block (trialCount is > 200)\n",
    "    # check if it's congruent or incongruent\n",
    "        # if congruent\n",
    "            # grab next row and add to the afterCongruent dataframe\n",
    "        # if incongruent\n",
    "            # grab next row and add to the afterIncongruent dataframe\n",
    "            \n",
    "testBlockDF = highAccDF.loc[highAccDF['currentBlockName'].isnull()]\n",
    "\n",
    "\n",
    "afterConDF = testBlockDF.loc[testBlockDF['imgCongruency'].shift(1) == 'c'] # can you just do this\n",
    "afterIncDF = testBlockDF.loc[testBlockDF['imgCongruency'].shift(1) == 'i']\n",
    "\n",
    "afterConDF.name = 'afterConDF'\n",
    "afterIncDF.name = 'afterIncDF'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "afterConDF AccPerc is 0.8829787234042553\n",
      "afterConDF avg resp time: 1027.4536817102137\n",
      "afterIncDF AccPerc is 0.8390532544378698\n",
      "afterIncDF avg resp time: 1036.0640569395018\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8390532544378698, 1036.0640569395018]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getAccAndRT(afterConDF)\n",
    "\n",
    "getAccAndRT(afterIncDF)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "605d4a00bd7b750a1832489ef299cdc74ad9753fbd4c8cd108b39010ae995421"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
