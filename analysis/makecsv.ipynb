{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fixDataLength(path):\n",
    "    '''\n",
    "    gets rid of the weird length stuff\n",
    "    path (string) : filepath to the .log file for a participant\n",
    "    '''     \n",
    "    x = open(path)\n",
    "    s = x.read().replace(',,,', ',NaN,NaN,')\n",
    "    x.close()\n",
    "\n",
    "    # Now open the file in write mode and write the string with replaced\n",
    "\n",
    "    x=open(path,'w')\n",
    "    x.write(s)\n",
    "    x.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAccAndRT(df):\n",
    "    '''\n",
    "    returns [array]: [reaction time, accuracy] for dataframe df\n",
    "    df needs to have ['respTime'] and ['accuracy'] columns, and a name\n",
    "    '''\n",
    "    accCount = df['accuracy'].astype(int).sum()\n",
    "\n",
    "    accPerc = accCount / len(df)\n",
    "    RTdf = df.loc[df['accuracy'] == 1] #remove mistake trials for RT calculation\n",
    "    RT = RTdf['respTime'].astype(float).mean()\n",
    "    \n",
    "    print(df.name + ' AccPerc is ' + str(accPerc))\n",
    "    print(df.name + ' avg resp time: ' + str(RT))\n",
    "    \n",
    "    return [accPerc, RT]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "am5tnxthwn6pz exists.\n",
      "aw5o1rk3w60fc exists.\n",
      "Creating csv file for a1msg3v72sbkvu\n",
      "Creating csv file for a3lxaru55pr281\n",
      "a1j980qnbdg17z exists.\n",
      "Creating csv file for a25pfsordo3swq\n",
      "a12b7sh0t31k8u exists.\n",
      "Creating csv file for a31nsutwp9a51h\n",
      "a3uaxlnvxordwj exists.\n",
      "Creating csv file for a2w6qfkxrq5fcp\n",
      "Creating csv file for a3nxt3ovgl7qnr\n",
      "a32j7anzoukv9n exists.\n",
      "awa928gj41l3a exists.\n",
      "Creating csv file for a1qcfzj4pfm9wi\n",
      "a3b2yrsmsc2j3t exists.\n",
      "aqaxdl1inqc9q exists.\n",
      "a1h198mrim37t1 exists.\n",
      "Creating csv file for a3ckwbnfp1zhbl\n",
      "a1m64r8hpynnza exists.\n",
      "a22cwnsgo4uvgo exists.\n",
      "aiyomf8pjjleq exists.\n",
      "Creating csv file for a1ime6dsk137x4\n",
      "awtcgy2cl1t68 exists.\n",
      "aiekcwyzts41v exists.\n",
      "a3q7072s2ngysl exists.\n",
      "ajq71yigy01hz exists.\n",
      "a2efmn1afprcl exists.\n",
      "Creating csv file for a1t6dmrdvola7x\n",
      "Creating group level csv file.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import copy\n",
    "\n",
    "#global script variables\n",
    "accCutoff = .65\n",
    "path = r'/Users/jinjiang-macair/Library/CloudStorage/OneDrive-DukeUniversity/Duke/Fall2022Rotation/Data/contextFlanker2.0/'\n",
    "\n",
    "#load files from path\n",
    "allFiles = glob.glob(path + \"*.txt\")\n",
    "assignmentID = allFiles\n",
    "subjectList = []\n",
    "assignmentList = []\n",
    "groupDataList = []\n",
    "aboveAccCutoff = []\n",
    "accList = []\n",
    "\n",
    "for file in allFiles:\n",
    "    # open participant info file\n",
    "    partInfoFile = open(file,\"r\").readlines()\n",
    "    partInfo = [x.strip() for x in partInfoFile]\n",
    "    \n",
    "    #pull worker ID and assignment ID from file\n",
    "    wID = partInfo[2]\n",
    "    aID = partInfo[1]\n",
    "    compID = wID.split(':')  #getting worker ID\n",
    "    compID2 = aID.split(':') #getting assignment ID\n",
    "    subject = compID[1] #subID\n",
    "    \n",
    "    #open log file with the same name as the given particant info file\n",
    "    logfile = compID2[1]+'.log'\n",
    "    \n",
    "    #fixDataLength(path+logfile) #dunno if i should return the log file instead of doing a void fxn here\n",
    "    \n",
    "    partDataFile = pd.read_csv(path + logfile, lineterminator=';', sep=',', header=None, error_bad_lines = False);\n",
    "    partData = pd.concat([partDataFile], ignore_index=True, axis = 1) \n",
    "    testData = copy.deepcopy(partData)\n",
    "    \n",
    "    #formatting result dataframe\n",
    "    \n",
    "    # these are longer than they seem.\n",
    "    partData['subject']=subject #adding a column with subID\n",
    "    partData = partData.rename(columns={0: 'expStage', 1: 'sectionType', 2: 'taskName', 3: 'blockNumber', 4: 'firstBlockName', 5: 'secondBlockName', 6: 'thirdBlockName', \n",
    "                                        7:'currentBlockName', 8: 'trialCount', 9: 'blockTrialCount', 10: 'flankerSize',\n",
    "                                        11: 'trialImg', 12: 'imgSource', 13:'imgCongruency', 14: 'imgDisplayLocation', 15:'repeat', \n",
    "                                        16: 'stimOnset', 17: 'respOnset', 18: 'respTime', 19: 'accuracy', 20: 'sectionStart', \n",
    "                                        21: 'sectionEnd', 22: 'sectionEnd-sectionStart', 23:'subject'}) \n",
    "       \n",
    "    #add info to individual lists\n",
    "    subjectList.append(subject)\n",
    "    assignmentList.append(compID2[1])\n",
    "    \n",
    "    #add data to whole sample dataframe list\n",
    "    groupDataList.append(partData)\n",
    "\n",
    "    #save out participant data to CSV if it doesn't exist already\n",
    "    if os.path.exists(path+'Subj_'+str(subject)+'.csv'):\n",
    "        print(subject+' exists.') #don't make csv again if it already exits (file creation times are helpful for keeping track of data)\n",
    "    else:\n",
    "        print('Creating csv file for '+subject)\n",
    "        partData.to_csv(path+'Subj_'+str(subject)+'.csv', index=False)\n",
    "    \n",
    "#combine groupData into one file and save file\n",
    "groupData = pd.concat(groupDataList, ignore_index = True)\n",
    "\n",
    "# save out groupData into csv\n",
    "print('Creating group level csv file.')\n",
    "groupData.to_csv(path+'combinedData'+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65        True\n",
       "66        True\n",
       "67        True\n",
       "68        True\n",
       "69        True\n",
       "         ...  \n",
       "13002     True\n",
       "13003    False\n",
       "13004     True\n",
       "13005    False\n",
       "13006     True\n",
       "Name: repeat, Length: 12320, dtype: object"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allData = pd.read_csv('/Users/jinjiang-macair/Library/CloudStorage/OneDrive-DukeUniversity/Duke/Fall2022Rotation/Data/contextFlanker2.0/combinedData.csv')\n",
    "\n",
    "allData = allData.loc[allData['sectionType'] == 'main1']\n",
    "\n",
    "allData['repeat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65       False\n",
       "66       False\n",
       "67       False\n",
       "68       False\n",
       "69       False\n",
       "         ...  \n",
       "13002    False\n",
       "13003     True\n",
       "13004    False\n",
       "13005     True\n",
       "13006    False\n",
       "Name: repeat, Length: 12320, dtype: bool"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#flip the repeat column cuz it was off by one...\n",
    "\n",
    "allData['repeat'] = ~allData['repeat'].astype(bool)\n",
    "\n",
    "allData['repeat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "accThreshold = 75\n",
    "\n",
    "highAccDF = pd.DataFrame()\n",
    "\n",
    "#subjectList.remove('a3ljsvb3hlepnw')\n",
    "\n",
    "for subject in subjectList:\n",
    "    subjectDF = allData.loc[allData['subject'] == subject]\n",
    "    \n",
    "    '''\n",
    "    Check if the accuracy of each subject is above our threshold.\n",
    "    If so, add it to the highAccDF.\n",
    "    '''\n",
    "    if (100 * subjectDF['accuracy'].astype(int).sum() / len(subjectDF)) > accThreshold:\n",
    "        highAccDF = pd.concat([highAccDF, subjectDF])\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conDF AccPerc is 0.909280303030303\n",
      "conDF avg resp time: 1013.9954176213289\n",
      "incDF AccPerc is 0.8880681818181818\n",
      "incDF avg resp time: 1034.744934954148\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8880681818181818, 1034.744934954148]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conDF = highAccDF.loc[(highAccDF['imgCongruency'] == 'c')]\n",
    "conDF.name = 'conDF'\n",
    "\n",
    "incDF = highAccDF.loc[(highAccDF['imgCongruency'] == 'i')]\n",
    "incDF.name = 'incDF'\n",
    "\n",
    "getAccAndRT(conDF)\n",
    "getAccAndRT(incDF)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to grab the respTime and Acc for each trial AFTER a congruent trial\n",
    "\n",
    "\n",
    "# make an empty dataframe for trials AFTER congruent ones\n",
    "# make another empty dataframe for trials after incongruent ones\n",
    "\n",
    "# for each row in the test block (trialCount is > 200)\n",
    "    # check if it's congruent or incongruent\n",
    "        # if congruent\n",
    "            # grab next row and add to the afterCongruent dataframe\n",
    "        # if incongruent\n",
    "            # grab next row and add to the afterIncongruent dataframe\n",
    "            \n",
    "# testBlockDF = highAccDF.loc[highAccDF['currentBlockName'].isnull()] #this is only for the first batch of participants cuz it was messed up\n",
    "\n",
    "testBlockDF = highAccDF.loc[highAccDF['currentBlockName'] == 'test']\n",
    "\n",
    "conTestDF = testBlockDF.loc[testBlockDF['imgCongruency'] == 'c']\n",
    "incTestDF = testBlockDF.loc[testBlockDF['imgCongruency'] == 'i']\n",
    "\n",
    "conTestDF.name = 'conTestDF'\n",
    "incTestDF.name = 'incTestDF'\n",
    "\n",
    "afterConTestDF = testBlockDF.loc[testBlockDF['imgCongruency'].shift(1) == 'c'] # can you just do this\n",
    "afterIncTestDF = testBlockDF.loc[testBlockDF['imgCongruency'].shift(1) == 'i']\n",
    "\n",
    "afterConTestDF.name = 'afterConTestDF'\n",
    "afterIncTestDF.name = 'afterIncTestDF'\n",
    "\n",
    "afterOldConTestDF = testBlockDF.loc[(testBlockDF['repeat'] == True) & (testBlockDF['imgCongruency'].shift(1) == 'c')]\n",
    "afterOldIncTestDF = testBlockDF.loc[(testBlockDF['repeat'] == True) & (testBlockDF['imgCongruency'].shift(1) == 'i')]\n",
    "\n",
    "afterOldConTestDF.name = 'afterOldConTestDF'\n",
    "afterOldIncTestDF.name = 'afterOldIncTestDF'\n",
    "\n",
    "afterNewConTestDF = testBlockDF.loc[(testBlockDF['repeat'] == False) & (testBlockDF['imgCongruency'].shift(1) == 'c')]\n",
    "afterNewIncTestDF = testBlockDF.loc[(testBlockDF['repeat'] == False) & (testBlockDF['imgCongruency'].shift(1) == 'i')]\n",
    "\n",
    "afterNewConTestDF.name = 'afterNewConTestDF'\n",
    "afterNewIncTestDF.name = 'afterNewIncTestDF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conTestDF AccPerc is 0.9184027777777778\n",
      "conTestDF avg resp time: 1013.7251417769376\n",
      "incTestDF AccPerc is 0.8972222222222223\n",
      "incTestDF avg resp time: 1036.3014705882354\n",
      "afterConTestDF AccPerc is 0.9065647794373046\n",
      "afterConTestDF avg resp time: 1023.6298850574713\n",
      "afterIncTestDF AccPerc is 0.9090277777777778\n",
      "afterIncTestDF avg resp time: 1026.1646294881589\n",
      "afterOldConTestDF AccPerc is 0.9055555555555556\n",
      "afterOldConTestDF avg resp time: 1025.9125766871166\n",
      "afterOldIncTestDF AccPerc is 0.8958333333333334\n",
      "afterOldIncTestDF avg resp time: 1026.3093023255815\n",
      "afterNewConTestDF AccPerc is 0.9075747046560111\n",
      "afterNewConTestDF avg resp time: 1021.3506891271056\n",
      "afterNewIncTestDF AccPerc is 0.9222222222222223\n",
      "afterNewIncTestDF avg resp time: 1026.0240963855422\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9222222222222223, 1026.0240963855422]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getAccAndRT(conTestDF)\n",
    "getAccAndRT(incTestDF)\n",
    "\n",
    "getAccAndRT(afterConTestDF)\n",
    "getAccAndRT(afterIncTestDF)\n",
    "\n",
    "getAccAndRT(afterOldConTestDF)\n",
    "getAccAndRT(afterOldIncTestDF)\n",
    "getAccAndRT(afterNewConTestDF)\n",
    "getAccAndRT(afterNewIncTestDF)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learnBlocksHighConDF AccPerc is 0.8929166666666667\n",
      "learnBlocksHighConDF avg resp time: 1021.0522631824545\n",
      "learnBlocksLowConDF AccPerc is 0.8825\n",
      "learnBlocksLowConDF avg resp time: 1025.9159584513693\n",
      "learnBlocksHighConCongruentTrialsDF AccPerc is 0.9005208333333333\n",
      "learnBlocksHighConCongruentTrialsDF avg resp time: 1014.733950260266\n",
      "learnBlocksHighConIncongruentTrialsDF AccPerc is 0.8625\n",
      "learnBlocksHighConIncongruentTrialsDF avg resp time: 1047.4396135265702\n",
      "learnBlocksLowConCongruentTrialsDF AccPerc is 0.8895833333333333\n",
      "learnBlocksLowConCongruentTrialsDF avg resp time: 1012.679156908665\n",
      "learnBlocksLowConIncongruentTrialsDF AccPerc is 0.8807291666666667\n",
      "learnBlocksLowConIncongruentTrialsDF avg resp time: 1029.258426966292\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8807291666666667, 1029.258426966292]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firstLearnBlockHighConDF = highAccDF.loc[(highAccDF['blockNumber'] == 1) & (highAccDF['firstBlockName'].isin(['learnBtop', 'learnBbot']))]\n",
    "firstLearnBlockHighConDF.name = 'firstLearnBlockHighConDF'\n",
    "\n",
    "secondLearnBlockHighConDF = highAccDF.loc[(highAccDF['blockNumber'] == 2) & (highAccDF['secondBlockName'].isin(['learnBtop', 'learnBbot']))]\n",
    "secondLearnBlockHighConDF.name = 'secondLearnBlockHighConDF'\n",
    "\n",
    "firstLearnBlockLowConDF = highAccDF.loc[(highAccDF['blockNumber'] == 1) & (highAccDF['firstBlockName'].isin(['learnAtop', 'learnAbot']))]\n",
    "firstLearnBlockLowConDF.name = 'firstLearnBlockLowConDF'\n",
    "\n",
    "secondLearnBlockLowConDF = highAccDF.loc[(highAccDF['blockNumber'] == 2) & (highAccDF['secondBlockName'].isin(['learnAtop', 'learnAbot']))]\n",
    "secondLearnBlockLowConDF.name = 'secondLearnBlockLowConDF'\n",
    "\n",
    "learnBlocksHighConDF = pd.concat([firstLearnBlockHighConDF, secondLearnBlockHighConDF])\n",
    "learnBlocksHighConDF.name = 'learnBlocksHighConDF'\n",
    "\n",
    "learnBlocksLowConDF = pd.concat([firstLearnBlockLowConDF, secondLearnBlockLowConDF])\n",
    "learnBlocksLowConDF.name = 'learnBlocksLowConDF'\n",
    "\n",
    "learnBlocksLowConCongruentTrialsDF = learnBlocksLowConDF.loc[learnBlocksLowConDF['imgCongruency'] == 'c']\n",
    "learnBlocksLowConCongruentTrialsDF.name = 'learnBlocksLowConCongruentTrialsDF'\n",
    "\n",
    "learnBlocksLowConIncongruentTrialsDF = learnBlocksLowConDF.loc[learnBlocksLowConDF['imgCongruency'] == 'i']\n",
    "learnBlocksLowConIncongruentTrialsDF.name = 'learnBlocksLowConIncongruentTrialsDF'\n",
    "\n",
    "learnBlocksHighConCongruentTrialsDF = learnBlocksHighConDF.loc[learnBlocksHighConDF['imgCongruency'] == 'c']\n",
    "learnBlocksHighConCongruentTrialsDF.name = 'learnBlocksHighConCongruentTrialsDF'\n",
    "\n",
    "learnBlocksHighConIncongruentTrialsDF = learnBlocksHighConDF.loc[learnBlocksHighConDF['imgCongruency'] == 'i']\n",
    "learnBlocksHighConIncongruentTrialsDF.name = 'learnBlocksHighConIncongruentTrialsDF'\n",
    "\n",
    "getAccAndRT(learnBlocksHighConDF)\n",
    "getAccAndRT(learnBlocksLowConDF)\n",
    "\n",
    "getAccAndRT(learnBlocksHighConCongruentTrialsDF)\n",
    "getAccAndRT(learnBlocksHighConIncongruentTrialsDF)\n",
    "\n",
    "getAccAndRT(learnBlocksLowConCongruentTrialsDF)\n",
    "getAccAndRT(learnBlocksLowConIncongruentTrialsDF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeatDF = testBlockDF.loc[testBlockDF['repeat'] == False] #doing False cuz the repeats are off by one...fix this later\n",
    "\n",
    "#but this needs to be for each subject though. Cuz every image should show up at some point in each condition.\n",
    "#highConContextDF = repeatDF.loc[repeatDF['imgSource'].isin(learnBlocksHighConDF['imgSource'])]\n",
    "\n",
    "#highConContextDF = repeatDF.loc[repeatDF['imgSource'].isin(learnBlocksHighConDF['imgSource']) & repeatDF['subject'].isin(learnBlocksHighConDF['subject'])]\n",
    "\n",
    "# use testBlockDF cuz it lets us do trial N+1. repeatDF gets rid of those.\n",
    "mergedHighConContextDF = pd.merge(testBlockDF, learnBlocksHighConDF, indicator=True, on=['imgSource', 'subject'], how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>expStage_x</th>\n",
       "      <th>sectionType_x</th>\n",
       "      <th>taskName_x</th>\n",
       "      <th>blockNumber_x</th>\n",
       "      <th>firstBlockName_x</th>\n",
       "      <th>secondBlockName_x</th>\n",
       "      <th>thirdBlockName_x</th>\n",
       "      <th>currentBlockName_x</th>\n",
       "      <th>trialCount_x</th>\n",
       "      <th>blockTrialCount_x</th>\n",
       "      <th>...</th>\n",
       "      <th>imgDisplayLocation_y</th>\n",
       "      <th>repeat_y</th>\n",
       "      <th>stimOnset_y</th>\n",
       "      <th>respOnset_y</th>\n",
       "      <th>respTime_y</th>\n",
       "      <th>accuracy_y</th>\n",
       "      <th>sectionStart_y</th>\n",
       "      <th>sectionEnd_y</th>\n",
       "      <th>sectionEnd-sectionStart_y</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>main1</td>\n",
       "      <td>contextFlankerMainTask</td>\n",
       "      <td>3.0</td>\n",
       "      <td>learnBtop</td>\n",
       "      <td>learnAbot</td>\n",
       "      <td>test</td>\n",
       "      <td>test</td>\n",
       "      <td>201.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>main1</td>\n",
       "      <td>contextFlankerMainTask</td>\n",
       "      <td>3.0</td>\n",
       "      <td>learnBtop</td>\n",
       "      <td>learnAbot</td>\n",
       "      <td>test</td>\n",
       "      <td>test</td>\n",
       "      <td>202.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>main1</td>\n",
       "      <td>contextFlankerMainTask</td>\n",
       "      <td>3.0</td>\n",
       "      <td>learnBtop</td>\n",
       "      <td>learnAbot</td>\n",
       "      <td>test</td>\n",
       "      <td>test</td>\n",
       "      <td>203.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>top</td>\n",
       "      <td>True</td>\n",
       "      <td>621648.0</td>\n",
       "      <td>622825.0</td>\n",
       "      <td>1177.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>main1</td>\n",
       "      <td>contextFlankerMainTask</td>\n",
       "      <td>3.0</td>\n",
       "      <td>learnBtop</td>\n",
       "      <td>learnAbot</td>\n",
       "      <td>test</td>\n",
       "      <td>test</td>\n",
       "      <td>204.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>main1</td>\n",
       "      <td>contextFlankerMainTask</td>\n",
       "      <td>3.0</td>\n",
       "      <td>learnBtop</td>\n",
       "      <td>learnAbot</td>\n",
       "      <td>test</td>\n",
       "      <td>test</td>\n",
       "      <td>205.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>main1</td>\n",
       "      <td>contextFlankerMainTask</td>\n",
       "      <td>3.0</td>\n",
       "      <td>learnBbot</td>\n",
       "      <td>learnAtop</td>\n",
       "      <td>test</td>\n",
       "      <td>test</td>\n",
       "      <td>436.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5756</td>\n",
       "      <td>NaN</td>\n",
       "      <td>main1</td>\n",
       "      <td>contextFlankerMainTask</td>\n",
       "      <td>3.0</td>\n",
       "      <td>learnBbot</td>\n",
       "      <td>learnAtop</td>\n",
       "      <td>test</td>\n",
       "      <td>test</td>\n",
       "      <td>437.0</td>\n",
       "      <td>237.0</td>\n",
       "      <td>...</td>\n",
       "      <td>bottom</td>\n",
       "      <td>True</td>\n",
       "      <td>351580.0</td>\n",
       "      <td>353176.0</td>\n",
       "      <td>1596.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5757</td>\n",
       "      <td>NaN</td>\n",
       "      <td>main1</td>\n",
       "      <td>contextFlankerMainTask</td>\n",
       "      <td>3.0</td>\n",
       "      <td>learnBbot</td>\n",
       "      <td>learnAtop</td>\n",
       "      <td>test</td>\n",
       "      <td>test</td>\n",
       "      <td>438.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5758</td>\n",
       "      <td>NaN</td>\n",
       "      <td>main1</td>\n",
       "      <td>contextFlankerMainTask</td>\n",
       "      <td>3.0</td>\n",
       "      <td>learnBbot</td>\n",
       "      <td>learnAtop</td>\n",
       "      <td>test</td>\n",
       "      <td>test</td>\n",
       "      <td>439.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5759</td>\n",
       "      <td>NaN</td>\n",
       "      <td>main1</td>\n",
       "      <td>contextFlankerMainTask</td>\n",
       "      <td>3.0</td>\n",
       "      <td>learnBbot</td>\n",
       "      <td>learnAtop</td>\n",
       "      <td>test</td>\n",
       "      <td>test</td>\n",
       "      <td>440.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5760 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     expStage_x sectionType_x              taskName_x  blockNumber_x  \\\n",
       "0           NaN         main1  contextFlankerMainTask            3.0   \n",
       "1           NaN         main1  contextFlankerMainTask            3.0   \n",
       "2           NaN         main1  contextFlankerMainTask            3.0   \n",
       "3           NaN         main1  contextFlankerMainTask            3.0   \n",
       "4           NaN         main1  contextFlankerMainTask            3.0   \n",
       "...         ...           ...                     ...            ...   \n",
       "5755        NaN         main1  contextFlankerMainTask            3.0   \n",
       "5756        NaN         main1  contextFlankerMainTask            3.0   \n",
       "5757        NaN         main1  contextFlankerMainTask            3.0   \n",
       "5758        NaN         main1  contextFlankerMainTask            3.0   \n",
       "5759        NaN         main1  contextFlankerMainTask            3.0   \n",
       "\n",
       "     firstBlockName_x secondBlockName_x thirdBlockName_x currentBlockName_x  \\\n",
       "0           learnBtop         learnAbot             test               test   \n",
       "1           learnBtop         learnAbot             test               test   \n",
       "2           learnBtop         learnAbot             test               test   \n",
       "3           learnBtop         learnAbot             test               test   \n",
       "4           learnBtop         learnAbot             test               test   \n",
       "...               ...               ...              ...                ...   \n",
       "5755        learnBbot         learnAtop             test               test   \n",
       "5756        learnBbot         learnAtop             test               test   \n",
       "5757        learnBbot         learnAtop             test               test   \n",
       "5758        learnBbot         learnAtop             test               test   \n",
       "5759        learnBbot         learnAtop             test               test   \n",
       "\n",
       "      trialCount_x  blockTrialCount_x  ... imgDisplayLocation_y repeat_y  \\\n",
       "0            201.0                1.0  ...                  NaN      NaN   \n",
       "1            202.0                2.0  ...                  NaN      NaN   \n",
       "2            203.0                3.0  ...                  top     True   \n",
       "3            204.0                4.0  ...                  NaN      NaN   \n",
       "4            205.0                5.0  ...                  NaN      NaN   \n",
       "...            ...                ...  ...                  ...      ...   \n",
       "5755         436.0              236.0  ...                  NaN      NaN   \n",
       "5756         437.0              237.0  ...               bottom     True   \n",
       "5757         438.0              238.0  ...                  NaN      NaN   \n",
       "5758         439.0              239.0  ...                  NaN      NaN   \n",
       "5759         440.0              240.0  ...                  NaN      NaN   \n",
       "\n",
       "     stimOnset_y respOnset_y respTime_y accuracy_y  sectionStart_y  \\\n",
       "0            NaN         NaN        NaN        NaN             NaN   \n",
       "1            NaN         NaN        NaN        NaN             NaN   \n",
       "2       621648.0    622825.0     1177.0        0.0             NaN   \n",
       "3            NaN         NaN        NaN        NaN             NaN   \n",
       "4            NaN         NaN        NaN        NaN             NaN   \n",
       "...          ...         ...        ...        ...             ...   \n",
       "5755         NaN         NaN        NaN        NaN             NaN   \n",
       "5756    351580.0    353176.0     1596.0        1.0             NaN   \n",
       "5757         NaN         NaN        NaN        NaN             NaN   \n",
       "5758         NaN         NaN        NaN        NaN             NaN   \n",
       "5759         NaN         NaN        NaN        NaN             NaN   \n",
       "\n",
       "      sectionEnd_y  sectionEnd-sectionStart_y     _merge  \n",
       "0              NaN                        NaN  left_only  \n",
       "1              NaN                        NaN  left_only  \n",
       "2              NaN                        NaN       both  \n",
       "3              NaN                        NaN  left_only  \n",
       "4              NaN                        NaN  left_only  \n",
       "...            ...                        ...        ...  \n",
       "5755           NaN                        NaN  left_only  \n",
       "5756           NaN                        NaN       both  \n",
       "5757           NaN                        NaN  left_only  \n",
       "5758           NaN                        NaN  left_only  \n",
       "5759           NaN                        NaN  left_only  \n",
       "\n",
       "[5760 rows x 47 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mergedHighConContextDF\n",
    "\n",
    "afterNewConTestDF = testBlockDF.loc[(testBlockDF['repeat'] == False) & (testBlockDF['imgCongruency'].shift(1) == 'c')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "605d4a00bd7b750a1832489ef299cdc74ad9753fbd4c8cd108b39010ae995421"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
